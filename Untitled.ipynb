{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fff66b-f4a0-40e3-9d6f-2eec26181ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def extract_and_aggregate_frames(video_path, sequence_length=10, frame_size=(224, 224), frame_sampling_rate=1):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    sequence = []  # List to store frames for aggregation\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "\n",
    "    while success:\n",
    "        if frame_count % frame_sampling_rate == 0:\n",
    "            resized_frame = cv2.resize(frame, frame_size)\n",
    "            sequence.append(resized_frame)\n",
    "\n",
    "            if len(sequence) == sequence_length:\n",
    "                # Process the aggregated sequence (e.g., save it, or further processing)\n",
    "                process_aggregated_sequence(sequence, count, video_path)\n",
    "\n",
    "                # Clear the sequence for the next set of frames\n",
    "                sequence = []\n",
    "\n",
    "                count += 1\n",
    "\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "def process_aggregated_sequence(sequence, sequence_number, video_path):\n",
    "    # Perform additional processing or save the aggregated sequence\n",
    "    aggregated_sequence_filename = f\"{os.path.splitext(video_path)[0]}_sequence_{sequence_number:04d}.npy\"\n",
    "    # For simplicity, let's save it as a numpy file\n",
    "    np.save(aggregated_sequence_filename, np.array(sequence))\n",
    "\n",
    "# Example usage with temporal aggregation\n",
    "input_video_path = \"C:/Users/dell/Documents/GitHub/anomaly-detection-for-voilence/dataset/anomaly/Fighting009_x264.mp4\"\n",
    "extract_and_aggregate_frames(input_video_path, sequence_length=10, frame_sampling_rate=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60949061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef808872-e817-4b6a-b2d4-45fca24efeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize frame to a consistent size if needed\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "anomaly_video_path = \"C:/Users/dell/Documents/GitHub/anomaly-detection-for-voilence/dataset/anomaly/Fighting009_x264.mp4\"\n",
    "anomaly_frames = preprocess_video(anomaly_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362d411b-893e-4aec-b897-daae2a81e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(frames):\n",
    "    # Simple frame differencing as a feature\n",
    "    differences = np.diff(frames, axis=0)\n",
    "    return np.mean(differences, axis=(1, 2, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c087f72-d428-4b91-8ec3-f81d43411cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train):\n",
    "    model = IsolationForest(contamination=0.1, random_state=42)\n",
    "    model.fit(X_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56f59b54-c260-44b2-93fc-6007ae9f4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions[predictions == 1] = 0  # Map inliers to 0 (normal), outliers to -1 (anomaly)\n",
    "\n",
    "    # Assuming ground truth labels are available\n",
    "    true_labels = np.array([0] * len(X_test[0]))  # Replace with your true labels\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "992989d7-d42a-4c97-9488-51ad2e3efa66",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 4) (3577503752.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[25], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    normal_video_path = \"\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 4)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    anomaly_video_path = \"path/to/anomaly/video.mp\"\n",
    "    normal_video_path = \"\n",
    "\n",
    "    anomaly_frames = preprocess_video(anomaly_video_path)\n",
    "    normal_frames = preprocess_video(normal_video_path)\n",
    "\n",
    "    anomaly_features = extract_features(anomaly_frames)\n",
    "    normal_features = extract_features(normal_frames)\n",
    "\n",
    "    X = np.concatenate([anomaly_features, normal_features], axis=0)\n",
    "    y = np.concatenate([np.ones(len(anomaly_features)), np.zeros(len(normal_features))], axis=0)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = train_model(X_train)\n",
    "\n",
    "    evaluate_model(model, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0f7ff97-e620-4e06-93a4-dc86a39024fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/your/trained_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f97e9-8c52-4edb-8e54-a4be7101326c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c087f72-d428-4b91-8ec3-f81d43411cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def extract_frames_from_folder(folder_path, output_folder, resize_shape=(224, 224), apply_noise_reduction=True, apply_optical_flow=True):\n",
    "    for video_filename in os.listdir(folder_path):\n",
    "        video_path = os.path.join(folder_path, video_filename)\n",
    "        output_subfolder = os.path.join(output_folder, video_filename.split('.')[0])\n",
    "\n",
    "        extract_frames(video_path, output_subfolder, resize_shape, apply_noise_reduction, apply_optical_flow)\n",
    "\n",
    "def extract_frames(video_path, output_folder, resize_shape=(224, 224), apply_noise_reduction=True, apply_optical_flow=True):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get frames per second (fps) and total number of frames\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    # Initialize previous frame for optical flow\n",
    "    prev_frame = None\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply noise reduction (Gaussian blur) if specified\n",
    "        if apply_noise_reduction:\n",
    "            frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "        # Resize the frame to the desired shape\n",
    "        frame = cv2.resize(frame, resize_shape)\n",
    "\n",
    "        # Convert the frame to uint8 if it's not already\n",
    "        if frame.dtype != 'uint8':\n",
    "            frame = (frame * 255).astype('uint8')\n",
    "\n",
    "        # Apply optical flow if specified\n",
    "        if apply_optical_flow and prev_frame is not None:\n",
    "            # Convert frames to grayscale\n",
    "            prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "            current_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Compute optical flow using Farneback method\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, current_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "\n",
    "            # Save optical flow as an image file\n",
    "            flow_filename = os.path.join(output_folder, f\"flow_{frame_count:04d}.jpg\")\n",
    "            save_optical_flow_image(flow, flow_filename)\n",
    "\n",
    "        # Save the frame as an image file\n",
    "        frame_filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "        frame_count += 1\n",
    "        prev_frame = frame\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    ####\n",
    "def save_optical_flow_image(flow, filename):\n",
    "    # Calculate polar coordinates\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "    # Convert polar coordinates to HSV color representation\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 1] = 255\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Convert HSV to BGR\n",
    "    flow_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Save the optical flow as an image file\n",
    "    cv2.imwrite(filename, flow_bgr)\n",
    "\n",
    "#####\n",
    "\n",
    "# Specify the paths to the \"normal\" and \"anomaly\" folders\n",
    "normal_folder_path = \"dataset/normal\"\n",
    "anomaly_folder_path = \"dataset/anomaly\"\n",
    "\n",
    "# Specify the output folders for frames and optical flow\n",
    "output_normal_folder = \"normal_output\"\n",
    "output_anomaly_folder = \"anomaly_output\"\n",
    "\n",
    "# Resize shape for the frames\n",
    "resize_shape = (224, 224)\n",
    "\n",
    "# Extract frames from the \"normal\" folder with noise reduction and optical flow\n",
    "extract_frames_from_folder(normal_folder_path, output_normal_folder, resize_shape, apply_noise_reduction=True, apply_optical_flow=True)\n",
    "\n",
    "# Extract frames from the \"anomaly\" folder with noise reduction and optical flow\n",
    "extract_frames_from_folder(anomaly_folder_path, output_anomaly_folder, resize_shape, apply_noise_reduction=True, apply_optical_flow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fb5896c-24f8-43af-aea4-345454735bfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Load and preprocess data for normal and anomaly classes using ResNet\u001b[39;00m\n\u001b[0;32m     36\u001b[0m normal_data, normal_labels \u001b[38;5;241m=\u001b[39m load_and_preprocess_frames(normal_folder_path, feature_extractor)\n\u001b[1;32m---> 37\u001b[0m anomaly_data, anomaly_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43manomaly_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Concatenate normal and anomaly data\u001b[39;00m\n\u001b[0;32m     40\u001b[0m all_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((normal_data, anomaly_data))\n",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m, in \u001b[0;36mload_and_preprocess_frames\u001b[1;34m(folder_path, model, resize_shape)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(video_folder_path):\n\u001b[0;32m     17\u001b[0m     frame_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(video_folder_path, frame_filename)\n\u001b[1;32m---> 18\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, resize_shape)\n\u001b[0;32m     20\u001b[0m     image \u001b[38;5;241m=\u001b[39m preprocess_input(image)  \u001b[38;5;66;03m# Preprocess according to ResNet requirements\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Function to load and preprocess frames using ResNet\n",
    "def load_and_preprocess_frames(folder_path, model, resize_shape=(224, 224)):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for video_folder in os.listdir(folder_path):\n",
    "        video_folder_path = os.path.join(folder_path, video_folder)\n",
    "        for frame_filename in os.listdir(video_folder_path):\n",
    "            frame_path = os.path.join(video_folder_path, frame_filename)\n",
    "            image = cv2.imread(frame_path)\n",
    "            image = cv2.resize(image, resize_shape)\n",
    "            image = preprocess_input(image)  # Preprocess according to ResNet requirements\n",
    "            data.append(image)\n",
    "            labels.append(1 if \"normal\" in folder_path else 0)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Specify the paths to the \"normal\" and \"anomaly\" folders\n",
    "normal_folder_path = \"normal_output\"\n",
    "anomaly_folder_path = \"anomaly_output\"\n",
    "\n",
    "# Load ResNet50 model pre-trained on ImageNet data\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Create a new model by removing the last layers of ResNet\n",
    "feature_extractor = Model(inputs=resnet_model.input, outputs=resnet_model.layers[-1].output)\n",
    "\n",
    "# Load and preprocess data for normal and anomaly classes using ResNet\n",
    "normal_data, normal_labels = load_and_preprocess_frames(normal_folder_path, feature_extractor)\n",
    "anomaly_data, anomaly_labels = load_and_preprocess_frames(anomaly_folder_path, feature_extractor)\n",
    "\n",
    "# Concatenate normal and anomaly data\n",
    "all_data = np.concatenate((normal_data, anomaly_data))\n",
    "all_labels = np.concatenate((normal_labels, anomaly_labels))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten the feature vectors for SVM\n",
    "X_train_flatten = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_flatten = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Train a Support Vector Machine (SVM) classifier\n",
    "svm_classifier = SVC(probability=True)\n",
    "svm_classifier.fit(X_train_flatten, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_classifier.predict(X_test_flatten)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35b40be2-87d0-44f0-82a3-b0d946187bd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 25.3 GiB for an array with shape (45059, 224, 224, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m anomaly_data, anomaly_labels \u001b[38;5;241m=\u001b[39m load_and_preprocess_frames(anomaly_folder_path, feature_extractor)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Concatenate normal and anomaly data\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m all_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manomaly_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((normal_labels, anomaly_labels))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Split data into training and testing sets\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 25.3 GiB for an array with shape (45059, 224, 224, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "######\n",
    "# Modify the load_and_preprocess_frames function\n",
    "def load_and_preprocess_frames(folder_path, model, resize_shape=(224, 224), batch_size=50):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for video_filename in os.listdir(folder_path):\n",
    "        video_path = os.path.join(folder_path, video_filename)\n",
    "        \n",
    "        # Extract frames from the video\n",
    "        frames = extract_frames(video_path, resize_shape=resize_shape)\n",
    "        \n",
    "        # Preprocess each frame using the ResNet model\n",
    "        preprocessed_frames = [preprocess_input(frame) for frame in frames]\n",
    "        \n",
    "        # Stack frames to create a 4D tensor\n",
    "        video_data = np.stack(preprocessed_frames, axis=0)\n",
    "        \n",
    "        # Append data and label\n",
    "        data.append(video_data)\n",
    "        labels.append(1 if \"normal\" in folder_path else 0)\n",
    "        \n",
    "        # Process in batches\n",
    "        if len(data) == batch_size:\n",
    "            yield np.concatenate(data), np.array(labels)\n",
    "            data, labels = [], []\n",
    "\n",
    "    # Process the remaining frames\n",
    "    if data:\n",
    "        yield np.concatenate(data), np.array(labels)\n",
    "\n",
    "# Now load and preprocess data for normal and anomaly classes using ResNet in batches\n",
    "batch_size = 50\n",
    "normal_data_batches = load_and_preprocess_frames(normal_folder_path, feature_extractor, batch_size=batch_size)\n",
    "anomaly_data_batches = load_and_preprocess_frames(anomaly_folder_path, feature_extractor, batch_size=batch_size)\n",
    "\n",
    "# Concatenate normal and anomaly data in batches\n",
    "all_data_batches = []\n",
    "all_labels_batches = []\n",
    "\n",
    "for normal_batch, anomaly_batch in zip(normal_data_batches, anomaly_data_batches):\n",
    "    batch_data, batch_labels = np.concatenate((normal_batch[0], anomaly_batch[0])), np.concatenate((normal_batch[1], anomaly_batch[1]))\n",
    "    all_data_batches.append(batch_data)\n",
    "    all_labels_batches.append(batch_labels)\n",
    "\n",
    "# Concatenate all batches\n",
    "all_data = np.concatenate(all_data_batches)\n",
    "all_labels = np.concatenate(all_labels_batches)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "######\n",
    "# Flatten the feature vectors for SVM\n",
    "X_train_flatten = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_flatten = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# Train a Support Vector Machine (SVM) classifier\n",
    "svm_classifier = SVC(probability=True)\n",
    "svm_classifier.fit(X_train_flatten, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_classifier.predict(X_test_flatten)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e7f75-4884-4a50-85f9-ad5a7dce6ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a8b92-1e72-4fa4-84ce-ff223eabbdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457abf25-eb70-4151-bebe-c9d69d252b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a83637-5f8a-4247-9e1f-d7df2163686b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
